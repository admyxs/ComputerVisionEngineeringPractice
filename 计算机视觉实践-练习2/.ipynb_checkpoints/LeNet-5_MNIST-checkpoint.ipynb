{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd15cdb9-b2de-4f42-bcc4-3bf92304656b",
   "metadata": {},
   "source": [
    "## 导入所需包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ec0bcc8-2a3c-486d-bc28-46c154aec692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,os\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e5ba7b-162d-468e-8c6a-7121f0a870b5",
   "metadata": {},
   "source": [
    "## 分别下载训练和测试数据集，并生成训练加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbcca87e-9087-4b15-b681-d148ffa66eb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root = os.getcwd()\n",
    "batch_size = 100\n",
    "# 加载数据时即将其转换为tensor并归一化\n",
    "train_dataset = dsets.MNIST(root, train=True, download=True,\n",
    "                            transform=transforms.Compose([transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "test_dataset = dsets.MNIST(root, train=False, download=True, \n",
    "                            transform=transforms.Compose([transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "# 生成训练loader和测试loader\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                           batch_size=batch_size,\n",
    "                             shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                           batch_size=batch_size,\n",
    "                            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a36c6b7-c490-4ba3-a4c1-67137f9014ec",
   "metadata": {},
   "source": [
    "## LeNet-5网络的定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1262d40-3ee5-4260-93fe-fd3ad3998bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet-5\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # 由于MNIST的大小为（1，28，28），所以需要微调第一层卷积，以适应大小，并并影响后续的大小\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),\n",
    "                                    nn.BatchNorm2d(6),\n",
    "                                    nn.Sigmoid(),\n",
    "                                    nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "                                    #nn.ReLU(),\n",
    "                                    #nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "                                    nn.BatchNorm2d(16),\n",
    "                                    nn.Sigmoid(),\n",
    "                                    nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "                                    #nn.ReLU(),\n",
    "                                    #nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.fc1 = nn.Sequential(nn.Linear(5 * 5 * 16, 120),\n",
    "                                 nn.Sigmoid(),\n",
    "                                 #nn.ReLU()\n",
    "                                )\n",
    "        self.fc2 = nn.Sequential(nn.Linear(120, 84),\n",
    "                                       nn.Sigmoid(),\n",
    "                                       #nn.ReLU()\n",
    "                                        )\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e0da64-b8a1-4604-a47f-51c0c51006d1",
   "metadata": {},
   "source": [
    "## 定义超参数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a23c706a-fb5e-4b04-b33d-6dec2f0ebe56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "LeNet5                                   [1, 10]                   --\n",
      "├─Sequential: 1-1                        [1, 6, 14, 14]            --\n",
      "│    └─Conv2d: 2-1                       [1, 6, 28, 28]            156\n",
      "│    └─BatchNorm2d: 2-2                  [1, 6, 28, 28]            12\n",
      "│    └─Sigmoid: 2-3                      [1, 6, 28, 28]            --\n",
      "│    └─AvgPool2d: 2-4                    [1, 6, 14, 14]            --\n",
      "├─Sequential: 1-2                        [1, 16, 5, 5]             --\n",
      "│    └─Conv2d: 2-5                       [1, 16, 10, 10]           2,416\n",
      "│    └─BatchNorm2d: 2-6                  [1, 16, 10, 10]           32\n",
      "│    └─Sigmoid: 2-7                      [1, 16, 10, 10]           --\n",
      "│    └─AvgPool2d: 2-8                    [1, 16, 5, 5]             --\n",
      "├─Sequential: 1-3                        [1, 120]                  --\n",
      "│    └─Linear: 2-9                       [1, 120]                  48,120\n",
      "│    └─Sigmoid: 2-10                     [1, 120]                  --\n",
      "├─Sequential: 1-4                        [1, 84]                   --\n",
      "│    └─Linear: 2-11                      [1, 84]                   10,164\n",
      "│    └─Sigmoid: 2-12                     [1, 84]                   --\n",
      "├─Linear: 1-5                            [1, 10]                   850\n",
      "==========================================================================================\n",
      "Total params: 61,750\n",
      "Trainable params: 61,750\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.42\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.10\n",
      "Params size (MB): 0.25\n",
      "Estimated Total Size (MB): 0.35\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 设置训练的epoch和类别、学习率\n",
    "num_epoches = 15\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = LeNet5(num_classes).to(device)\n",
    "\n",
    "# 打印网络结构\n",
    "print(summary(net, input_size=(1, 1, 28, 28)))\n",
    "\n",
    "# 使用交叉熵损失函数和Adam优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr = learning_rate)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e716a83-da28-42bd-a534-954be032a136",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaeb9ae2-4a99-4541-a40c-32eb44c6edf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch = 0\n",
      "current loss = 0.12002\n",
      "current loss = 0.11871\n",
      "current loss = 0.12202\n",
      "current loss = 0.06819\n",
      "current loss = 0.14308\n",
      "current loss = 0.05920\n",
      "current epoch = 1\n",
      "current loss = 0.05992\n",
      "current loss = 0.08761\n",
      "current loss = 0.13995\n",
      "current loss = 0.04504\n",
      "current loss = 0.04317\n",
      "current loss = 0.10423\n",
      "current epoch = 2\n",
      "current loss = 0.04506\n",
      "current loss = 0.03247\n",
      "current loss = 0.01951\n",
      "current loss = 0.07144\n",
      "current loss = 0.12947\n",
      "current loss = 0.05771\n",
      "current epoch = 3\n",
      "current loss = 0.05938\n",
      "current loss = 0.03938\n",
      "current loss = 0.04929\n",
      "current loss = 0.01695\n",
      "current loss = 0.01790\n",
      "current loss = 0.05649\n",
      "current epoch = 4\n",
      "current loss = 0.14095\n",
      "current loss = 0.01549\n",
      "current loss = 0.05712\n",
      "current loss = 0.02347\n",
      "current loss = 0.07653\n",
      "current loss = 0.02211\n",
      "current epoch = 5\n",
      "current loss = 0.04737\n",
      "current loss = 0.04687\n",
      "current loss = 0.06797\n",
      "current loss = 0.14027\n",
      "current loss = 0.09600\n",
      "current loss = 0.04838\n",
      "current epoch = 6\n",
      "current loss = 0.02235\n",
      "current loss = 0.10927\n",
      "current loss = 0.07473\n",
      "current loss = 0.04993\n",
      "current loss = 0.01821\n",
      "current loss = 0.02262\n",
      "current epoch = 7\n",
      "current loss = 0.08904\n",
      "current loss = 0.04008\n",
      "current loss = 0.02752\n",
      "current loss = 0.05719\n",
      "current loss = 0.03051\n",
      "current loss = 0.07540\n",
      "current epoch = 8\n",
      "current loss = 0.01787\n",
      "current loss = 0.01288\n",
      "current loss = 0.11747\n",
      "current loss = 0.11230\n",
      "current loss = 0.03990\n",
      "current loss = 0.00937\n",
      "current epoch = 9\n",
      "current loss = 0.04443\n",
      "current loss = 0.02629\n",
      "current loss = 0.06835\n",
      "current loss = 0.04456\n",
      "current loss = 0.09128\n",
      "current loss = 0.07812\n",
      "current epoch = 10\n",
      "current loss = 0.06278\n",
      "current loss = 0.01117\n",
      "current loss = 0.02898\n",
      "current loss = 0.03642\n",
      "current loss = 0.01292\n",
      "current loss = 0.08870\n",
      "current epoch = 11\n",
      "current loss = 0.00695\n",
      "current loss = 0.01758\n",
      "current loss = 0.00525\n",
      "current loss = 0.01255\n",
      "current loss = 0.01199\n",
      "current loss = 0.02190\n",
      "current epoch = 12\n",
      "current loss = 0.01742\n",
      "current loss = 0.00442\n",
      "current loss = 0.02223\n",
      "current loss = 0.00761\n",
      "current loss = 0.02463\n",
      "current loss = 0.02590\n",
      "current epoch = 13\n",
      "current loss = 0.00863\n",
      "current loss = 0.10385\n",
      "current loss = 0.02060\n",
      "current loss = 0.00450\n",
      "current loss = 0.01484\n",
      "current loss = 0.02923\n",
      "current epoch = 14\n",
      "current loss = 0.00372\n",
      "current loss = 0.02017\n",
      "current loss = 0.00741\n",
      "current loss = 0.03475\n",
      "current loss = 0.03841\n",
      "current loss = 0.00956\n",
      "train_accuracy = 99.19%\n",
      "Accuracy = 98.94%\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('./logs')\n",
    "for epoch in range(num_epoches):\n",
    "    print('current epoch = %d' % epoch)\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs = net(images) \n",
    "        \n",
    "        # 训练损失\n",
    "        train_loss = criterion(outputs, labels) \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print('current loss = %.5f' % train_loss.item())\n",
    "        \n",
    "        # 训练准确率\n",
    "        _, predicts = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicts == labels).sum()\n",
    "        train_accuracy = correct / total\n",
    "        if epoch == num_epoches-1 and i == len(train_loader)-1:\n",
    "            print('train_accuracy = %.2f' % (100 * train_accuracy) + '%')\n",
    "\n",
    "    # 测试准确率\n",
    "    eval_total=0\n",
    "    eval_correct=0\n",
    "    for images, labels in test_loader:\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs = net(images) \n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        eval_total += labels.size(0)\n",
    "        eval_correct += (pred == labels).sum()\n",
    "        test_accuracy = eval_correct / eval_total\n",
    "\n",
    "    writer.add_scalar(\"loss\", train_loss, epoch)\n",
    "    writer.add_scalar(\"train accuracy\", train_accuracy, epoch)\n",
    "    writer.add_scalar(\"test accuracy\", test_accuracy, epoch)\n",
    "print('Accuracy = %.2f' % (100 * eval_correct / eval_total) + '%')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a625f28b-6923-4b50-8f4c-75009179005a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf79add6-0fc1-42cd-8202-0c64560f3465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
